{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Importing Dependecies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainingmonitor import TrainingMonitor\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 - Data Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workingDir = 'E:\\Machine Learning\\Real Data Test\\data\\main/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 - Initialzing DataFrame...\n",
      "\n",
      "Path Dropped: .csv\n",
      "Path Dropped: .csv\n",
      "Numbers of Images succefully imported: 4116\n"
     ]
    }
   ],
   "source": [
    "os.listdir()\n",
    "\n",
    "## Data Directory Path\n",
    "print('#1 - Initialzing DataFrame...\\n')\n",
    "imageID_Path = os.listdir(workingDir)\n",
    "\n",
    "## Creating data frame based on directory contents \n",
    "imagePath_df = pd.DataFrame({'ID':[n.split('.')[0] for n in imageID_Path],\n",
    "                                'Path':[workingDir + n for n in imageID_Path]})\n",
    "\n",
    "## Extracting features of images from the CSV file\n",
    "csv_dataPath = os.path.join(workingDir,'data_compressed.csv')\n",
    "imageFeatures_df = pd.read_csv(csv_dataPath, sep=',', encoding = 'ISO-8859-1')\n",
    "\n",
    "## COnvoerting all values to integer values\n",
    "imagePath_df[\"ID\"]= pd.to_numeric(imagePath_df[\"ID\"],errors='coerce')\n",
    "\n",
    "\n",
    "\n",
    "## Error handling for none JPEG Images\n",
    "\n",
    "for i,row in imagePath_df.iterrows():\n",
    "    picture_Path = row['Path']\n",
    "    # print(picture_Path)\n",
    "    extCheck = len(picture_Path)\n",
    "    path = picture_Path[extCheck-4:]\n",
    "    if (path != 'JPEG'):\n",
    "        print(\"Path Dropped:\", path)\n",
    "        imagePath_df.drop(i, inplace=True)\n",
    "\n",
    "\n",
    "print( \"Numbers of Images succefully imported:\",len(imagePath_df))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Dataframes...\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(left=imagePath_df, right=imageFeatures_df, on='ID', how='inner', )\n",
    "\n",
    "print('Merging Dataframes...')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Data...\n"
     ]
    }
   ],
   "source": [
    "## Validating the data\n",
    "print('Cleaning Data...')\n",
    "\n",
    "\n",
    "merged_df['Hammer Price'] = pd.to_numeric(merged_df['Hammer Price'], errors='coerce')\n",
    "\n",
    "merged_df = merged_df.replace(np.nan, 0)\n",
    "\n",
    "# merged_df['Low Estimation Price'].replace(np.nan, 0)\n",
    "\n",
    "means = []\n",
    "\n",
    "for i, row in merged_df.iterrows():\n",
    "\n",
    "    if(row['Low Estimation Price'] == 0 and row['High Estimation Price'] == 0):\n",
    "        mean = row['Hammer Price'] / 2\n",
    "    \n",
    "    elif (row['Low Estimation Price'] == 0):\n",
    "        mean = row['High Estimation Price'] / 2\n",
    "    else:\n",
    "        mean = (row['Low Estimation Price'] + row['High Estimation Price']) / 2\n",
    "    means.append(mean)\n",
    "    if(row['Hammer Price'] == 0.0): \n",
    "        merged_df.loc[i, 'Hammer Price'] = mean\n",
    "\n",
    "\n",
    "# \n",
    "merged_df['Mean Estimation'] = pd.Series(means)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing Data...\n"
     ]
    }
   ],
   "source": [
    "print('Normalizing Data...')\n",
    "CntRem = 0\n",
    "for i in range(len(merged_df)):\n",
    "        picture_Path = merged_df.at[i,'Path']\n",
    "        if not os.path.exists(picture_Path):\n",
    "                print(\"Oops! File gone on vacation:\", picture_Path)\n",
    "        # os.remove(merged_df.at[i,'Path'])\n",
    "        # merged_df.drop(merged_df.at[merged_df.index[i]], axis=0)\n",
    "\n",
    "        # print(\"Image\", merged_df.at[i,'ID'],\" to be removed\")\n",
    "\n",
    "# print(\"Total number of files removed\", CntRem)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Loading Images to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Creating List for Compressed Numpy array data paths\n",
    "import os.path \n",
    "\n",
    "test_df = merged_df\n",
    "\n",
    "\n",
    "images = []\n",
    "id = []\n",
    "IMAGE_RESIZE = (256,256)\n",
    "\n",
    "\n",
    "for i, row in merged_df.iterrows():\n",
    "\n",
    "    ## ASsigning iamge path the picture path\n",
    "    picture_Path = row['Path']\n",
    "    iD = row = row[\"ID\"]\n",
    "\n",
    "    if os.path.exists(picture_Path):\n",
    "        # Reading Image Path, Color Correcting, and then resizing\n",
    "        pic_bgr_arr = cv2.imread(picture_Path)\n",
    "        \n",
    "        if(pic_bgr_arr is not None):\n",
    "            pic_rgb_arr = cv2.cvtColor(pic_bgr_arr, cv2.COLOR_BGR2RGB)\n",
    "            pic_rgb_arr = cv2.resize(pic_rgb_arr, IMAGE_RESIZE)\n",
    "            pic_rgb_arr = pic_rgb_arr / 255.0\n",
    "        else:\n",
    "            print(\"Error with Image\", picture_Path)\n",
    "            # os.remove(picture_Path)\n",
    "            # merged_df.drop(i, inplace=True)\n",
    "\n",
    "        # Append to Image List\n",
    "        images.append(pic_rgb_arr)\n",
    "        id.append(iD)\n",
    "    \n",
    "    else:\n",
    "        continue\n",
    "       \n",
    "    \n",
    "\n",
    "# ZIP contents to load into datafram\n",
    "dfData = list(zip(id, images))\n",
    "images_df = pd.DataFrame(dfData, columns=['ID', 'Image'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // merging with dataframe\n",
    "merged_df = pd.merge(left=merged_df, right=images_df, on='ID', how='inner')\n",
    "\n",
    "merged_df.drop(['Low Estimation Price', 'High Estimation Price', 'Hammer Price', 'Size', 'Path', 'ID',   'Mean Estimation', 'Artist'],inplace=True, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    }
   ],
   "source": [
    "print(len(merged_df[\"Medium\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# le = LabelEncoder()\n",
    "\n",
    "# merged_df['Artist'] = le.fit_transform(merged_df['Artist'])\n",
    "# artistLabels = le.classes_\n",
    "\n",
    "# # artistLabels = np.array(artistLabels).ravel()\n",
    "# artistLabels\n",
    "\n",
    "# # labelEncoer_df = pd.DataFrame(artistLE, columns = artistLabels)\n",
    "\n",
    "# oneHot_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tober\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'toarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11644\\2849168588.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mlabels_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Medium'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'toarray'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# # from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# # # #creating instance of one-hot-encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "le = LabelEncoder()\n",
    "# # \n",
    "# labels_df = pd.DataFrame(le.fit_transform(merged_df[['Medium']]).toarray(), columns=le.categories_)\n",
    "# len(labels_df)\n",
    "\n",
    "# # # #perform one-hot encoding on 'team' column \n",
    "encoder_df = pd.DataFrame(encoder.fit_transform(merged_df[['Medium']]).toarray(), columns=encoder.categories_)\n",
    "# # # len(encoder_df)\n",
    "\n",
    "labels = encoder.categories_\n",
    "labels = np.array(labels).ravel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Path</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Low Estimation Price</th>\n",
       "      <th>High Estimation Price</th>\n",
       "      <th>Hammer Price</th>\n",
       "      <th>Size</th>\n",
       "      <th>Medium</th>\n",
       "      <th>Mean Estimation</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500.0</td>\n",
       "      <td>E:\\Machine Learning\\Real Data Test\\data\\main/5...</td>\n",
       "      <td>Ole Kielberg</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.165556</td>\n",
       "      <td>0.175945</td>\n",
       "      <td>42cm-59cm(16.54in-23.23in)</td>\n",
       "      <td>73</td>\n",
       "      <td>0.187017</td>\n",
       "      <td>[[[0.5254901960784314, 0.5058823529411764, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>E:\\Machine Learning\\Real Data Test\\data\\main/0...</td>\n",
       "      <td>Sam Nhlengethwa</td>\n",
       "      <td>0.186037</td>\n",
       "      <td>0.172988</td>\n",
       "      <td>0.158943</td>\n",
       "      <td>30cm-33cm(11.81in-12.99in)</td>\n",
       "      <td>68</td>\n",
       "      <td>0.178622</td>\n",
       "      <td>[[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3971.0</td>\n",
       "      <td>E:\\Machine Learning\\Real Data Test\\data\\main/3...</td>\n",
       "      <td>I. H. Brandt</td>\n",
       "      <td>0.187017</td>\n",
       "      <td>0.177469</td>\n",
       "      <td>0.163806</td>\n",
       "      <td>12cm-17.5cm(4.72in-6.89in)</td>\n",
       "      <td>73</td>\n",
       "      <td>0.181777</td>\n",
       "      <td>[[[0.7803921568627451, 0.7529411764705882, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3283.0</td>\n",
       "      <td>E:\\Machine Learning\\Real Data Test\\data\\main/3...</td>\n",
       "      <td>Sam Francis</td>\n",
       "      <td>0.114949</td>\n",
       "      <td>0.111269</td>\n",
       "      <td>0.100360</td>\n",
       "      <td>63.2cm-90.5cm(24.88in-35.63in)</td>\n",
       "      <td>68</td>\n",
       "      <td>0.112948</td>\n",
       "      <td>[[[1.0, 0.9921568627450981, 1.0], [1.0, 0.9882...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3974.0</td>\n",
       "      <td>E:\\Machine Learning\\Real Data Test\\data\\main/3...</td>\n",
       "      <td>Svend Sinding Christensen</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.177469</td>\n",
       "      <td>0.177469</td>\n",
       "      <td>63.5cm-77cm(25in-30.31in)</td>\n",
       "      <td>73</td>\n",
       "      <td>0.202362</td>\n",
       "      <td>[[[0.807843137254902, 0.8117647058823529, 0.77...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                               Path  \\\n",
       "0   500.0  E:\\Machine Learning\\Real Data Test\\data\\main/5...   \n",
       "1     0.0  E:\\Machine Learning\\Real Data Test\\data\\main/0...   \n",
       "2  3971.0  E:\\Machine Learning\\Real Data Test\\data\\main/3...   \n",
       "3  3283.0  E:\\Machine Learning\\Real Data Test\\data\\main/3...   \n",
       "4  3974.0  E:\\Machine Learning\\Real Data Test\\data\\main/3...   \n",
       "\n",
       "                      Artist  Low Estimation Price  High Estimation Price  \\\n",
       "0               Ole Kielberg             -0.000000               0.165556   \n",
       "1            Sam Nhlengethwa              0.186037               0.172988   \n",
       "2               I. H. Brandt              0.187017               0.177469   \n",
       "3                Sam Francis              0.114949               0.111269   \n",
       "4  Svend Sinding Christensen             -0.000000               0.177469   \n",
       "\n",
       "   Hammer Price                            Size  Medium  Mean Estimation  \\\n",
       "0      0.175945      42cm-59cm(16.54in-23.23in)      73         0.187017   \n",
       "1      0.158943      30cm-33cm(11.81in-12.99in)      68         0.178622   \n",
       "2      0.163806      12cm-17.5cm(4.72in-6.89in)      73         0.181777   \n",
       "3      0.100360  63.2cm-90.5cm(24.88in-35.63in)      68         0.112948   \n",
       "4      0.177469       63.5cm-77cm(25in-30.31in)      73         0.202362   \n",
       "\n",
       "                                               Image  \n",
       "0  [[[0.5254901960784314, 0.5058823529411764, 0.4...  \n",
       "1  [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...  \n",
       "2  [[[0.7803921568627451, 0.7529411764705882, 0.6...  \n",
       "3  [[[1.0, 0.9921568627450981, 1.0], [1.0, 0.9882...  \n",
       "4  [[[0.807843137254902, 0.8117647058823529, 0.77...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_Arr = encoder_df.to_numpy()\n",
    "encoderLen = len(encoder_Arr)\n",
    "encoderSeries = []\n",
    "\n",
    "for i in range(encoderLen): \n",
    "    encoderSeries.append(encoder_Arr[i])\n",
    "    # print(np.array_str(encoder_Arr[i], max_line_width=np.inf))\n",
    "\n",
    "merged_df['OneHot'] = pd.Series(encoderSeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop(['Medium'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Medium</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>[[[0.5254901960784314, 0.5058823529411764, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>[[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>[[[0.7803921568627451, 0.7529411764705882, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>[[[1.0, 0.9921568627450981, 1.0], [1.0, 0.9882...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73</td>\n",
       "      <td>[[[0.807843137254902, 0.8117647058823529, 0.77...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Medium                                              Image\n",
       "0      73  [[[0.5254901960784314, 0.5058823529411764, 0.4...\n",
       "1      68  [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...\n",
       "2      73  [[[0.7803921568627451, 0.7529411764705882, 0.6...\n",
       "3      68  [[[1.0, 0.9921568627450981, 1.0], [1.0, 0.9882...\n",
       "4      73  [[[0.807843137254902, 0.8117647058823529, 0.77..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.loc[1,\"OneHot\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 500, 116)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "shuffled_df = merged_df.sample(frac=1)\n",
    "train_df, val_df, test_df = shuffled_df[:3500], shuffled_df[3500:4000], shuffled_df[4000:]\n",
    "\n",
    "len(train_df), len(val_df), len(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Medium</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[0.5137254901960784, 0.38823529411764707, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3695</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[0.36470588235294116, 0.4, 0.298039215686274...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3842</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[0.996078431372549, 1.0, 1.0], [1.0, 1.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>0</td>\n",
       "      <td>[[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Medium                                              Image\n",
       "1599       0  [[[0.5137254901960784, 0.38823529411764707, 0....\n",
       "3695       0  [[[0.36470588235294116, 0.4, 0.298039215686274...\n",
       "2042       0  [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...\n",
       "3842       0  [[[0.996078431372549, 1.0, 1.0], [1.0, 1.0, 0....\n",
       "2035       0  [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_X_y(df):\n",
    "\n",
    "    dfArr = np.array(df)\n",
    "\n",
    "    x_pic = []\n",
    "    y_medium = []\n",
    "\n",
    "    for i in range(len(df)): \n",
    "\n",
    "        pic = dfArr[i, 0]\n",
    "        x_pic.append(pic)\n",
    "\n",
    "        medium = dfArr[i, 1]\n",
    "        y_medium.append(medium)\n",
    "\n",
    "    X_pic = np.asarray(x_pic)\n",
    "    y_medium = np.asarray(y_medium)\n",
    "\n",
    "\n",
    "    return X_pic, y_medium \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (115,3500) into shape (1,3500)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11644\\1949281421.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_pic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_val_pic\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_test_pic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11644\\1298232690.py\u001b[0m in \u001b[0;36mget_X_y\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdfArr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mx_pic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tober\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2064\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2066\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;32mc:\\Users\\Tober\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tober\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mvalues\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  10890\u001b[0m         \"\"\"\n\u001b[0;32m  10891\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10892\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10894\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mdeprecate_nonkeyword_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"self\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tober\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mas_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1597\u001b[0m                     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;31m# The underlying data was copied within _interleave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tober\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1645\u001b[0m                 \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1646\u001b[0m                 \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1647\u001b[1;33m                 \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1648\u001b[0m                 \u001b[0mitemmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1649\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (115,3500) into shape (1,3500)"
     ]
    }
   ],
   "source": [
    "X_train_pic, y_train = get_X_y(train_df)\n",
    "\n",
    "X_val_pic,  y_val = get_X_y(val_df)\n",
    "\n",
    "X_test_pic, y_test = get_X_y(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Y_train_art[0]\n",
    "# X_train_picTensor = tf.convert_to_tensor(X_train_pic, dtype=\"float32\")\n",
    "# Y_trainEstTensor = tf.convert_to_tensor(Y_train_est, dtype=\"float32\")\n",
    "\n",
    "# X_val_picTensor = tf.convert_to_tensor(X_val_pic, dtype=\"float32\")\n",
    "# Y_valEstTensor = tf.convert_to_tensor(Y_val_est, dtype=\"float32\")\n",
    "\n",
    "# valData = [X_val_picTensor, Y_valEstTensor]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.optimizers import  Adam\n",
    "\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y_train_one_hot = to_categorical(y_train)\n",
    "# y_val_one_hot = to_categorical(y_val)\n",
    "# y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "#############################\n",
    "\n",
    "activation = 'sigmoid'\n",
    "\n",
    "feature_extractor = Sequential()\n",
    "feature_extractor.add(Conv2D(32, 3, activation = activation, padding = 'same', input_shape = (256, 256, 3)))\n",
    "feature_extractor.add(BatchNormalization())\n",
    "\n",
    "feature_extractor.add(Conv2D(32, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "feature_extractor.add(BatchNormalization())\n",
    "feature_extractor.add(MaxPooling2D())\n",
    "\n",
    "feature_extractor.add(Conv2D(64, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "feature_extractor.add(BatchNormalization())\n",
    "\n",
    "feature_extractor.add(Conv2D(64, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "feature_extractor.add(BatchNormalization())\n",
    "feature_extractor.add(MaxPooling2D())\n",
    "\n",
    "feature_extractor.add(Flatten())\n",
    "\n",
    "#Add layers for deep learning prediction\n",
    "x = feature_extractor.output  \n",
    "x = Dense(128, activation = activation, kernel_initializer = 'he_uniform')(x)\n",
    "prediction_layer = Dense(115, activation = 'softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new model combining both feature extractor and x\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "cnn_model = Model(inputs=feature_extractor.input, outputs=prediction_layer)\n",
    "cnn_model.compile(optimizer=optimizer,loss = 'categorical_crossentropy', metrics = ['categorical_accuracy', \"accuracy\"])\n",
    "print(cnn_model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(\"e:\\\\Machine Learning\\\\Real Data Test\\\\logs\\\\VisualPlot\")\n",
    "\n",
    "savePlots = \"e:\\\\Machine Learning\\\\Real Data Test\\\\logs\\\\VisualPlot\\\\\"\n",
    "saveModel = \"e:\\\\Machine Learning\\\\Real Data Test\\\\savedModels\\\\\"\n",
    "\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.today().strftime('%b-%d-%Y-%H-%M')\n",
    "\n",
    "figPath = savePlots + 'featureExtraction1-'+date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSavePath = saveModel + \"featureExtraction1-\" + date +'\\\\'+'featureExtraction1.epoch{epoch:02d}-loss{val_loss:.2f}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(monitor='val_accuracy', filepath=modelSavePath, save_best_only=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modelSavePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [TrainingMonitor(figPath), checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the CNN model\n",
    "history = cnn_model.fit(x=X_train_pic, y=y_train, batch_size=16, epochs=5, validation_data = (X_val_pic, y_val), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_NN = cnn_model.predict(X_test_pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_NN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_NN = np.argmax(prediction_NN, axis=-1)\n",
    "y_test = encoder.inverse_transform(y_test)\n",
    "prediction_NN = encoder.inverse_transform(prediction_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_NN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(zip(y_test, prediction_NN))\n",
    "results_df = pd.DataFrame(results, columns=['Actual', 'Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# cm = confusion_matrix(y_test, prediction_NN)\n",
    "# print(cm)\n",
    "# sns.heatmap(cm, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 56\n",
    "\n",
    "img = X_test_pic[n]\n",
    "plt.imshow(img)\n",
    "input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "prediction = cnn_model.predict(input_img).flatten()  #argmax to convert categorical back to original\n",
    "prediction = encoder.inverse_transform([prediction])  #Reverse the label encoder to original name\n",
    "print(\"The prediction for this image is: \", prediction)\n",
    "print(\"The actual label for this image is: \", y_test[n])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Using Random Forest for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let us use features from convolutional network for RF\n",
    "X_for_RF = feature_extractor.predict(X_train_pic) #This is out X input to RF\n",
    "\n",
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
    "\n",
    "y_train['OneHot'] = encoder.inverse_transform(y_train['OneHot'])\n",
    "\n",
    "y_train['OneHot'] = le.fit_transform(merged_df['OneHot'])\n",
    "# Train the model on training data\n",
    "RF_model.fit(X_for_RF, y_train) #For sklearn no one hot encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send test data through same feature extractor process\n",
    "X_test_feature = feature_extractor.predict(X_test_pic)\n",
    "#Now predict using the trained RF model. \n",
    "prediction_RF = RF_model.predict(X_test_feature)\n",
    "#Inverse le transform to get original label back. \n",
    "prediction_RF = le.inverse_transform(prediction_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(test_labels, prediction_RF))\n",
    "\n",
    "#Confusion Matrix - verify accuracy of each class\n",
    "cm = confusion_matrix(test_labels, prediction_RF)\n",
    "#print(cm)\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "#Check results on a few select images\n",
    "#n=5 #dog park. RF works better than CNN\n",
    "n=9 #Select the index of image to be loaded for testing\n",
    "img = x_test[n]\n",
    "plt.imshow(img)\n",
    "input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "input_img_features=feature_extractor.predict(input_img)\n",
    "prediction_RF = RF_model.predict(input_img_features)[0] \n",
    "prediction_RF = le.inverse_transform([prediction_RF])  #Reverse the label encoder to original name\n",
    "print(\"The prediction for this image is: \", prediction_RF)\n",
    "print(\"The actual label for this image is: \", test_labels[n])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
